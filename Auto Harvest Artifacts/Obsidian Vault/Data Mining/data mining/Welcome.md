1. Εισαγωγή
Στην παρούσα εργασία εφαρμόζουμε και συγκρίνουμε διάφορες τεχνικές εξόρυξης δεδομένων σε δύο σύνολα δεδομένων. Αρχικά, χρησιμοποιούμε αλγορίθμους κατηγοριοποίησης για να διαχωρίσουμε τα emails σε spam και μη-spam. Στη συνέχεια, αναλύουμε τα δεδομένα επίδοσης μαθητών με μεθόδους συσταδοποίησης για να εντοπίσουμε ομάδες με παρόμοια χαρακτηριστικά. Τέλος, εξάγουμε κανόνες συσχέτισης από το σύνολο δεδομένων των μαθητών για να ανακαλύψουμε ενδιαφέροντα πρότυπα. Στόχος μας είναι να αξιολογήσουμε την αποτελεσματικότητα των διαφορετικών αλγορίθμων και να σχολιάσουμε τα αποτελέσματα για κάθε περίπτωση.

. Κατηγοριοποίηση (Classification)

2.1 Περιγραφή Συνόλου Δεδομένων  
Το σύνολο δεδομένων spam περιλαμβάνει 4601 emails, καθένα από τα οποία περιγράφεται από 9 χαρακτηριστικά:  
- cap_ave: μέσο μήκος συνεχόμενης ακολουθίας κεφαλαίων γραμμάτων  
- remove, ooo, money, free, our: ποσοστά εμφάνισης συγκεκριμένων λέξεων  
- char_$, char_!: ποσοστά εμφάνισης των συμβόλων $ και !  
- class: κατηγορία (spam ή email)  
Όλα τα χαρακτηριστικά κρίθηκαν σημαντικά για το πρόβλημα, καθώς σχετίζονται άμεσα με συνήθεις πρακτικές spam.

2.2 Προεπεξεργασία Δεδομένων  
Αρχικά, χρησιμοποιήθηκαν όλα τα διαθέσιμα χαρακτηριστικά. Για την αντιμετώπιση της ανισορροπίας μεταξύ των κατηγοριών (1813 spam, 2788 email), εφαρμόστηκε η τεχνική oversampling SMOTE. Ο υπολογισμός του ποσοστού SMOTE έγινε ώστε να εξισωθούν οι δύο κατηγορίες (περίπου 54%). Η χρήση του SMOTE βελτίωσε σημαντικά την ανίχνευση spam, με μικρή αύξηση των false positives. Η αξιολόγηση των αλγορίθμων έγινε με 10-fold cross-validation.

2.3 Αλγόριθμοι Κατηγοριοποίησης  
Εφαρμόστηκαν και συγκρίθηκαν οι εξής αλγόριθμοι:
- Naive Bayes: Απλός και γρήγορος, κατάλληλος για baseline.
- IBk (k-Nearest Neighbors): Βασίζεται σε ομοιότητα με γειτονικά emails.
- Random Forest: Συνδυασμός πολλών δέντρων για μεγαλύτερη ακρίβεια.
- J48 (C4.5 Decision Tree): Παρέχει ερμηνεύσιμα αποτελέσματα και ενσωματώνει επιλογή χαρακτηριστικών.

2.4 Πειραματική Διαδικασία & Αποτελέσματα  
Για κάθε αλγόριθμο, πραγματοποιήθηκε 10-fold cross-validation και καταγράφηκαν:
- Ακρίβεια (Correctly Classified Instances)
- Kappa Statistic (συμφωνία πέραν της τύχης)
- Πίνακας σύγχυσης (Confusion Matrix)
- Μετρικές ανά κατηγορία: Recall, Precision, F-Measure, ROC/PRC Area

**Naive Bayes χωρίς SMOTE:**  
Ακρίβεια: 86.55%.  
Recall για spam: 0.689, Precision για spam: 0.957.  
False Positives (legitimate ως spam): 56.  
False Negatives (spam ως legitimate): 563.  
Το μοντέλο είχε πολύ καλή αναγνώριση των legitimate emails, αλλά χαμηλότερη ανίχνευση spam.

**Naive Bayes με SMOTE:**  
Ακρίβεια: 88.09%.  
Recall για spam: 0.734, Precision για spam: 0.953.  
False Positives: 66.  
False Negatives: 482.  
Η χρήση SMOTE αύξησε σημαντικά την ανίχνευση spam, με μικρή αύξηση των false positives.

**IBk με SMOTE:**  
Ακρίβεια: 87.24%.  
Recall για spam: 0.864, Precision για spam: 0.821.  
False Positives: 341.  
False Negatives: 246.  
Υψηλή ανίχνευση spam αλλά αυξημένα false positives.

**Random Forest με SMOTE:**  
Ακρίβεια: 88.20%.  
Recall για spam: 0.874, Precision για spam: 0.834.  
False Positives: 315.  
False Negatives: 228.  
Πολύ καλή ισορροπία recall/precision, με σχετικά υψηλά false positives.

**J48 με SMOTE:**  
Ακρίβεια: 90.28%.  
Recall για spam: 0.873, Precision για spam: 0.880.  
False Positives: 216.  
False Negatives: 231.  
Το J48 πέτυχε την υψηλότερη συνολική ακρίβεια, το καλύτερο Kappa (0.7963), και τον χαμηλότερο αριθμό false positives, διατηρώντας πολύ υψηλό recall για spam.

2.5 Συζήτηση και Συμπέρασμα  
Η χρήση του SMOTE βελτίωσε την απόδοση όλων των αλγορίθμων, κυρίως στην ανίχνευση spam (αύξηση recall για spam). Ο J48 με SMOTE αποτελεί την καλύτερη επιλογή, καθώς συνδυάζει υψηλή ακρίβεια, χαμηλά false positives και πολύ καλή ανίχνευση spam. Η ισορροπία μεταξύ recall και precision, καθώς και το χαμηλό ποσοστό λανθασμένων ταξινομήσεων legitimate emails ως spam, καθιστούν τον J48 ιδανικό για το συγκεκριμένο πρόβλημα.

---

Συσταδοποίηση (Clustering)
3.1 Προεπεξεργασία Δεδομένων
Για τη συσταδοποίηση χρησιμοποιήθηκε το σύνολο δεδομένων Student Performance, το οποίο περιλαμβάνει βαθμούς μαθητών σε διάφορα μαθήματα και επιπλέον χαρακτηριστικά. Από τα διαθέσιμα γνωρίσματα, επιλέχθηκαν τα τρία αριθμητικά (π.χ. βαθμοί σε Math, Portuguese, Science) για την ανάλυση, καθώς μόνο αυτά μπορούν να χρησιμοποιηθούν απευθείας από τους αλγορίθμους συσταδοποίησης. Τα δεδομένα κανονικοποιήθηκαν ώστε να έχουν συγκρίσιμη κλίμακα και αφαιρέθηκαν τυχόν ακραίες τιμές (outliers) όπου κρίθηκε απαραίτητο.

3.2 K-Means και Elbow Method
Για τον προσδιορισμό του κατάλληλου αριθμού συστάδων εφαρμόστηκε η μέθοδος Elbow, όπου υπολογίστηκε το άθροισμα των τετραγώνων των αποστάσεων (inertia) για διάφορες τιμές του k. Η γραφική παράσταση εμφάνισε "αγκώνα" για k=3, που επιλέχθηκε ως βέλτιστη τιμή. Η εφαρμογή του αλγορίθμου K-Means με k=3 οδήγησε στη δημιουργία τριών διακριτών ομάδων μαθητών, οι οποίες διαφέρουν ως προς τη συνολική τους επίδοση. Οι συστάδες αυτές αντανακλούν ομάδες με χαμηλή, μέτρια και υψηλή επίδοση.

3.3 Ιεραρχική Συσταδοποίηση
Εφαρμόστηκε ιεραρχική συσταδοποίηση (agglomerative clustering) με χρήση του συνδέσμου Ward. Το δενδρόγραμμα που προέκυψε επιβεβαίωσε την ύπαρξη τριών κύριων συστάδων, αντίστοιχων με τα αποτελέσματα του K-Means. Η ιεραρχική ανάλυση προσφέρει επιπλέον οπτική για τις μεταξύ τους αποστάσεις και τη δομή των ομάδων.

3.4 DBSCAN
Ο αλγόριθμος DBSCAN εφαρμόστηκε για την ανίχνευση συστάδων με αυθαίρετο σχήμα και εντοπισμό θορύβου (outliers). Με βάση το γράφημα k-distance, επιλέχθηκε τιμή epsilon=0.5 και min_samples=5. Ο DBSCAN εντόπισε δύο κύριες συστάδες και ορισμένα σημεία ως θόρυβο, τα οποία δεν ανήκουν σε καμία ομάδα. Αυτό δείχνει ότι υπάρχουν μαθητές με ιδιαίτερα χαρακτηριστικά που διαφέρουν σημαντικά από το σύνολο.

3.5 Συζήτηση
Κάθε μέθοδος συσταδοποίησης ανέδειξε διαφορετικές πτυχές της δομής των δεδομένων. Το K-Means και η ιεραρχική συσταδοποίηση συμφωνούν ως προς τον αριθμό και τη σύσταση των κύριων ομάδων, ενώ ο DBSCAN ανέδειξε και την ύπαρξη outliers. Οι συστάδες που προέκυψαν μπορούν να χρησιμοποιηθούν για στοχευμένες παρεμβάσεις ή περαιτέρω ανάλυση της επίδοσης των μαθητών.

---

4. Εξαγωγή Κανόνων Συσχέτισης (Association Rules)

Για το τρίτο μέρος, εφαρμόστηκε ο αλγόριθμος Apriori στο σύνολο Student Performance. Η προεπεξεργασία (διακριτοποίηση) περιγράφεται στο [Discretization](Section%20C/1.%20Preprocessing/Discretization.md). Τα αποτελέσματα και οι σχολιασμοί των κανόνων βρίσκονται στο φάκελο [Apriori](Section%20C/Apriori).

---

5. Συμπεράσματα  
Η συνολική αξιολόγηση και τα συμπεράσματα για κάθε τεχνική παρουσιάζονται στα αντίστοιχα αρχεία συμπερασμάτων κάθε ενότητας.
